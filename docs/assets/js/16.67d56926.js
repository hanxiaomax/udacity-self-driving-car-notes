(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{231:function(t,s,a){"use strict";a.r(s);var n=a(0),o=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"content"},[a("h1",{attrs:{id:"路径规划器的实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#路径规划器的实现","aria-hidden":"true"}},[t._v("#")]),t._v(" 路径规划器的实现")]),a("h2",{attrs:{id:"_1-伪代码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-伪代码","aria-hidden":"true"}},[t._v("#")]),t._v(" 1. 伪代码")]),a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),a("span",{attrs:{class:"token constant"}},[t._v("A")]),a("span",{attrs:{class:"token operator"}},[t._v("*")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("//初始化已经探索过的节点为空")]),t._v("\n    closedSet "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("// 初始化未探索的节点，开始时仅包含起点")]),t._v("\n    openSet "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("//cameFrom是一个字典，键是当前节点，\b值是当前节点的父节点")]),t._v("\n    cameFrom "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" the empty map\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("// gScore为一个字典，\b\b存放该点的gsocre，起点为0，其余点初始化为无穷")]),t._v("\n    gScore "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" map "),a("span",{attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("default")]),t._v(" value "),a("span",{attrs:{class:"token keyword"}},[t._v("of")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("Infinity")]),t._v("\n    gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v(" \n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("// fScore为一个字典，\b\b存放该点的fsocre F = G + H，")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("//因此起点为起点到终点的直线距离，其余点初始化为无穷 ")]),t._v("\n    fScore "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" map "),a("span",{attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("default")]),t._v(" value "),a("span",{attrs:{class:"token keyword"}},[t._v("of")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("Infinity")]),t._v("\n    fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("heuristic_cost_estimate")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" openSet is not empty\n         "),a("span",{attrs:{class:"token comment"}},[t._v("//取出F值最小的节点设为当前点")]),t._v("\n        current "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" the node "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" openSet having the lowest fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" value            "),a("span",{attrs:{class:"token comment"}},[t._v("//当前点为目标点，跳出循环返回路径，并通过camefrom来生成路径（逆序）")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" current "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" goal\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("reconstruct_path")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{attrs:{class:"token comment"}},[t._v("//将该点从\b待探索集中移除，放入已探索集")]),t._v("\n        openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("Remove")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("Add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{attrs:{class:"token comment"}},[t._v("//遍历当前节点的所有邻居节点（需要在未探索集中）")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" each neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("of")]),t._v(" current\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" closedSet\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),t._v("  \n\n            "),a("span",{attrs:{class:"token comment"}},[t._v("//Discover a new node")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" not neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("    \n                    self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token function"}},[t._v("add")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                \n            "),a("span",{attrs:{class:"token comment"}},[t._v("//计算tentative_gScore作为新路径的gScore")]),t._v("\n            "),a("span",{attrs:{class:"token comment"}},[t._v("//tentative_gScore可以理解为假设移动到临接点之后点gscore")]),t._v("\n            tentative_gScore "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("dist_between")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),a("span",{attrs:{class:"token comment"}},[t._v("//类似冒泡排序，首先存一个最小耗散的点（初始时可能是任意的，然后如果发现比它小的就替换掉，否则使用原来的路径）")]),t._v("\n            "),a("span",{attrs:{class:"token comment"}},[t._v("//新gScore>=原gScore，则按照原路径（移动后好散增加了）")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" tentative_gScore "),a("span",{attrs:{class:"token operator"}},[t._v(">=")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n\n            "),a("span",{attrs:{class:"token comment"}},[t._v("// 否则选择gScore较小的新路径，并更新G值与F值。同时更新节点的父子关系。")]),t._v("\n            cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" current\n            gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tentative_gScore\n            fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("heuristic_cost_estimate")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" failure\n    "),a("span",{attrs:{class:"token comment"}},[t._v("//从caomeFrom中从goal点追溯到start点，取得路径节点。")]),t._v("\n\n")])]),a("h2",{attrs:{id:"_2-基于函数实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-基于函数实现","aria-hidden":"true"}},[t._v("#")]),t._v(" 2. 基于函数实现")]),a("p",[t._v("这里直接引用\n"),a("a",{attrs:{href:"https://github.com/jluiz20/udacity_python_a_start_route_planner/blob/master/student_code.py",target:"_blank",rel:"noopener noreferrer"}},[t._v("jluiz20/udacity_python_a_start_route_planner")]),t._v("的\b实现")]),a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" math\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("shortest_path")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("M"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("print")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v('"shortest path called, Start"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"Goal"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),a("span",{attrs:{class:"token comment"}},[t._v("#the set already explored")]),t._v("\n    closedSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("set")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),a("span",{attrs:{class:"token comment"}},[t._v("#only the start node is known")]),t._v("\n    openSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    \n    "),a("span",{attrs:{class:"token comment"}},[t._v("#the dictionary with the parent with the best way until the node")]),t._v("\n    cameFrom "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),a("span",{attrs:{class:"token comment"}},[t._v("#cost of getting from the start to the node")]),t._v("\n    gScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v("\n    \n    fScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("#the straight line distance between start and goal")]),t._v("\n    fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" distance"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("goal"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        current "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_lowest_value"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        "),a("span",{attrs:{class:"token comment"}},[t._v("# If reached the goal, YEAH!")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" current "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("print")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v('"Goal Reached!"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" reconstruct_path"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n        openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("remove"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("#remove from open")]),t._v("\n        closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("#mark as processed")]),t._v("\n                \n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("roads"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),t._v("\n            \n            "),a("span",{attrs:{class:"token comment"}},[t._v("#add the neighbor to the frontier")]),t._v("\n            openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                \n            "),a("span",{attrs:{class:"token comment"}},[t._v("#The distance from start to a neighbor")]),t._v("\n            tentative_gScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" distance"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n                "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" tentative_gScore "),a("span",{attrs:{class:"token operator"}},[t._v(">=")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("# This is not a better path.")]),t._v("\n            \n            "),a("span",{attrs:{class:"token comment"}},[t._v("# This path is the best until now. Record it!")]),t._v("\n            cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" current\n            gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tentative_gScore\n            fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" distance"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" M"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("goal"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n        \n"),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("reconstruct_path")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    total_path "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("list")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    total_path"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insert"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" current "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        current "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        total_path"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insert"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" total_path\n    \n"),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("node_lowest_value")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    lowest_node "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("35767")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("#large number")]),t._v("\n    lowest_value "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("float")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'inf'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" node "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" lowest_value"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                lowest_node "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" node\n                lowest_value "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" lowest_node\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("distance")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("p2"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    distance "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v("p2"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("**")]),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("+")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p1"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v("p2"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("**")]),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" distance\n")])]),a("h2",{attrs:{id:"_3-基于类的实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-基于类的实现","aria-hidden":"true"}},[t._v("#")]),t._v(" 3. 基于类的实现")]),a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{attrs:{class:"token class-name"}},[t._v("PathPlanner")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token triple-quoted-string string"}},[t._v('"""Construct a PathPlanner Object"""')]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("__init__")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" M"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" goal"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token triple-quoted-string string"}},[t._v('""" """')]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" M\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" start\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" goal\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" goal "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" goal "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" goal "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" goal "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" goal "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run_search"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    \n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("create_closedSet")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("set")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("create_openSet")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("raise")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ValueError"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"Must create start node before creating an open set. Try running PathPlanner.set_start(start_node)"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("create_cameFrom")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("create_gScore")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        gScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromkeys"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token builtin"}},[t._v("float")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'inf'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" gScore\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("create_fScore")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        fScore"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromkeys"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token builtin"}},[t._v("float")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'inf'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distance"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" fScore\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("_reset")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run_search"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("get_path")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token triple-quoted-string string"}},[t._v('""" Reconstructs path after search """')]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path \n        "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run_search"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("set_map")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" M"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_reset"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" M\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("set_start")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_reset"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" start\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("set_goal")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_reset"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" goal\n    \n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("get_current_node")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        lowest_node "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("9999")]),t._v(" \n        lowest_value "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("float")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'inf'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" node "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore "),a("span",{attrs:{class:"token operator"}},[t._v("and")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("<")]),t._v(" lowest_value"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                lowest_node "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" node\n                lowest_value "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" lowest_node\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("get_neighbors")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("roads"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("get_gScore")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("get_tenative_gScore")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distance"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("is_open_empty")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("len")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("==")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("distance")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_1"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_2"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        distance "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" math"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_1"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v("node_2"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("**")]),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("+")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_1"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v("node_2"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token operator"}},[t._v("**")]),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" distance\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("heuristic_cost_estimate")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("distance"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("intersections"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("calculate_fscore")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("heuristic_cost_estimate"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("record_best_path_to")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" current \n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_tenative_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("calculate_fscore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("reconstruct_path")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token triple-quoted-string string"}},[t._v('""" Reconstructs path after search """')]),t._v("\n        total_path "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" current "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            current "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            total_path"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" total_path\n\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{attrs:{class:"token function"}},[t._v("run_search")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token triple-quoted-string string"}},[t._v('""" """')]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{attrs:{class:"token builtin"}},[t._v("map")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("raise")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ValueError"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"Must create map before running search. Try running PathPlanner.set_map(start_node)"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("raise")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ValueError"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"Must create goal node before running search. Try running PathPlanner.set_goal(start_node)"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("raise")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ValueError"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v('"Must create start node before running search. Try running PathPlanner.set_start(start_node)"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v("  self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cameFrom "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v("  self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_cameFrom"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gScore "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v("  self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fScore "),a("span",{attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),t._v("  self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create_fScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("not")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_open_empty"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            current "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_current_node"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" current "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("goal"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("x "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("reversed")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reconstruct_path"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("else")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("remove"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_neighbors"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("closedSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),t._v("    "),a("span",{attrs:{class:"token comment"}},[t._v("# Ignore the neighbor which is already evaluated.")]),t._v("\n\n                    "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("not")]),t._v(" neighbor "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("    "),a("span",{attrs:{class:"token comment"}},[t._v("# Discover a new node")]),t._v("\n                        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("openSet"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                "),a("span",{attrs:{class:"token comment"}},[t._v("# The distance from start to a neighbor")]),t._v("\n                "),a("span",{attrs:{class:"token comment"}},[t._v('#the "dist_between" function may vary as per the solution requirements.')]),t._v("\n                "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_tenative_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v(">=")]),t._v(" self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_gScore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{attrs:{class:"token keyword"}},[t._v("continue")]),t._v("        "),a("span",{attrs:{class:"token comment"}},[t._v("# This is not a better path.")]),t._v("\n\n                "),a("span",{attrs:{class:"token comment"}},[t._v("# This path is the best until now. Record it!")]),t._v("\n                self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("record_best_path_to"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neighbor"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("print")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v('"No Path Found"')]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        self"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n")])]),a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("if __name__ == '__main__':\n    planner = PathPlanner(map_40, 5, 34)\n    path = planner.path\n")])]),a("hr"),a("div",{staticClass:"tip custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("参考\b链接")]),a("p",[t._v("1."),a("a",{attrs:{href:"https://github.com/jluiz20/udacity_python_a_start_route_planner/blob/master/student_code.py",target:"_blank",rel:"noopener noreferrer"}},[t._v("jluiz20/udacity_python_a_start_route_planner")]),t._v("的\b实现")])])])}],!1,null,null,null);s.default=o.exports}}]);