<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>智能驾驶学习笔记 | 深度神经网络</title>
    <meta name="description" content="by Lingfeng Ai">
    <link rel="icon" href="/udacity-self-driving-car-notes/logo.png">
  <link rel="manifest" href="/udacity-self-driving-car-notes/manifest.json">
  <meta name="theme-color" content="#3eaf7c">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon" href="/udacity-self-driving-car-notes/icons/apple-touch-icon-152x152.png">
  <link rel="mask-icon" href="/udacity-self-driving-car-notes/icons/safari-pinned-tab.svg" color="#3eaf7c">
  <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
  <meta name="msapplication-TileColor" content="#000000">
    
    <link rel="preload" href="/udacity-self-driving-car-notes/assets/css/39.styles.324ff695.css" as="style"><link rel="preload" href="/udacity-self-driving-car-notes/assets/js/app.f0029fc6.js" as="script"><link rel="preload" href="/udacity-self-driving-car-notes/assets/js/11.8ca08bba.js" as="script"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/0.c09a41e5.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/1.44fdd069.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/2.a775a9b9.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/3.46ef3ea8.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/4.6539292a.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/5.c3b971c4.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/6.a764889e.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/7.ebb3565b.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/8.db44090d.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/9.a1b7e960.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/10.e1303d2e.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/12.64526326.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/13.a2ba6b10.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/14.214ecf56.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/15.04e68051.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/16.05634d92.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/17.c68418aa.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/18.198d027b.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/19.cbd0e516.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/20.ff1ca196.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/21.3e809f59.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/22.dabc3e2f.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/23.326234d7.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/24.4b8ef11b.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/25.b3001cd9.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/26.4fe09e74.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/27.55448bc7.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/28.be240f99.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/29.21614022.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/30.f5741409.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/31.466a81e1.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/32.ef09f9cf.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/33.b63b80f3.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/34.b0b031a9.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/35.ba365681.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/36.5e6181c6.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/37.9c521dde.js"><link rel="prefetch" href="/udacity-self-driving-car-notes/assets/js/38.97529aa0.js">
    <link rel="stylesheet" href="/udacity-self-driving-car-notes/assets/css/39.styles.324ff695.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div><a href="/udacity-self-driving-car-notes/" class="home-link router-link-active"><!----><span class="site-name">
      智能驾驶学习笔记
    </span></a><div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""><!----></div><nav class="nav-links can-hide"><div class="nav-item"><a href="/udacity-self-driving-car-notes/" class="nav-link">主页</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title">笔记</span><span class="arrow right"></span></a><ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----><a href="/udacity-self-driving-car-notes/posts/intro-self-driving-car/" class="nav-link">无人驾驶入门</a></li><li class="dropdown-item"><!----><a href="/udacity-self-driving-car-notes/posts/self-driving-car/" class="nav-link router-link-active">无人驾驶工程师</a></li><li class="dropdown-item"><!----><a href="/udacity-self-driving-car-notes/posts/others/" class="nav-link">未归类</a></li></ul></div></div><div class="nav-item"><a href="/udacity-self-driving-car-notes/res/" class="nav-link">资源</a></div><div class="nav-item"><a href="/udacity-self-driving-car-notes/contact/" class="nav-link">联系</a></div><a href="https://github.com/hanxiaomax/udacity-self-driving-car-notes/" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header><div class="sidebar-mask"></div><div class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/udacity-self-driving-car-notes/" class="nav-link">主页</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title">笔记</span><span class="arrow right"></span></a><ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----><a href="/udacity-self-driving-car-notes/posts/intro-self-driving-car/" class="nav-link">无人驾驶入门</a></li><li class="dropdown-item"><!----><a href="/udacity-self-driving-car-notes/posts/self-driving-car/" class="nav-link router-link-active">无人驾驶工程师</a></li><li class="dropdown-item"><!----><a href="/udacity-self-driving-car-notes/posts/others/" class="nav-link">未归类</a></li></ul></div></div><div class="nav-item"><a href="/udacity-self-driving-car-notes/res/" class="nav-link">资源</a></div><div class="nav-item"><a href="/udacity-self-driving-car-notes/contact/" class="nav-link">联系</a></div><a href="https://github.com/hanxiaomax/udacity-self-driving-car-notes/" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav><ul class="sidebar-links"><li><div class="sidebar-group first collapsable"><p class="sidebar-heading"><span>1. 计算机视觉基础</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>2. 计算机视觉进阶</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>3. 深度学习</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading open"><span>4. tersorflow</span><span class="arrow down"></span></p><ul class="sidebar-group-items"><li><a href="/udacity-self-driving-car-notes/posts/self-driving-car/tensorflow.html" class="sidebar-link">深度学习库——Tensorflow</a></li><li><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html" class="active sidebar-link">深度神经网络</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_1-深度神经网络简介" class="sidebar-link">1. 深度神经网络简介</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_1-线性模型复杂度" class="sidebar-link">1. 线性模型复杂度</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_2-rectified-linear-units（relus）" class="sidebar-link">2. Rectified Linear Units（ReLUs）</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_3-multilayer-neural-networks" class="sidebar-link">3. Multilayer Neural Networks</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_4-链式法则及反向传播" class="sidebar-link">4. 链式法则及反向传播</a></li></ul></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_2-基于tensorflow的深度神经网络" class="sidebar-link">2. 基于tensorflow的深度神经网络</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_1-例程" class="sidebar-link">1.  例程</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_2-训练神经网络" class="sidebar-link">2. 训练神经网络</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_3-储存变量和模型" class="sidebar-link">3. 储存变量和模型</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_4-加载参数到新的模型" class="sidebar-link">4. 加载参数到新的模型</a></li><li class="sidebar-sub-header"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/deepnetwork.html#_4-正规化" class="sidebar-link">4. 正规化</a></li></ul></li></ul></li></ul></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>5. 卷积神经网络</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>6. 基于LeNet的信号灯分类</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>7. Keras</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>8. 迁移学习</span><span class="arrow right"></span></p><!----></div></li><li><div class="sidebar-group collapsable"><p class="sidebar-heading"><span>9. 卡尔曼滤波</span><span class="arrow right"></span></p><!----></div></li></ul></div><div class="page"><div class="content"><h1 id="深度神经网络"><a href="#深度神经网络" aria-hidden="true" class="header-anchor">#</a> 深度神经网络</h1><h2 id="_1-深度神经网络简介"><a href="#_1-深度神经网络简介" aria-hidden="true" class="header-anchor">#</a> 1. 深度神经网络简介</h2><h3 id="_1-线性模型复杂度"><a href="#_1-线性模型复杂度" aria-hidden="true" class="header-anchor">#</a> 1. 线性模型复杂度</h3><p><img src="/udacity-self-driving-car-notes/assets/img/15380065684643.7ea292a2.jpg" alt></p><p>线性模型中，可调参数个数=w维数展开+b维数展开，即当我们有N个输入，K个输出时，我们的可调参数个数为(N+1)K</p><p><img src="/udacity-self-driving-car-notes/assets/img/15380065956269.8a2c4456.jpg" alt></p><ul><li>线性模型比较稳定，因为数据是线性叠加的，微小的输入不会引起结果的剧烈变化</li><li>因为模型是线性的，所以能够表示的关系是有限的，只能表示线性关系（输入是相加而非相乘）</li><li>线性函数的导数是常量</li><li>我们希望模型是非线性的，但是参数存放在线性的方程中，因此我们必须添加非线性成分</li><li>我们需要大量的可调参数，而不是固定的(N+1)K个</li></ul><h3 id="_2-rectified-linear-units（relus）"><a href="#_2-rectified-linear-units（relus）" aria-hidden="true" class="header-anchor">#</a> 2. Rectified Linear Units（ReLUs）</h3><p><img src="/udacity-self-driving-car-notes/assets/img/15380072209022.8eca863f.jpg" alt></p><p><img src="/udacity-self-driving-car-notes/assets/img/15380073455603.935647aa.jpg" alt></p><p>为了解决上一节提出的问题，我们引入<strong>ReLU</strong>函数，将其插入到矩阵中。以往，我们在构造多层的神经网络时，不同层的W是相乘的，然后得到一个W作为整体参与到结果的运算中，现在我们需要在Wi相乘的过程中插入<strong>ReLUs</strong>，这样模型就变成非线性模型来，同时我们可以调节隐藏层<strong>ReLUs</strong>的数量以达到增加参数的目的。</p><div class="tip custom-block"><p class="custom-block-title">注意</p><p><strong>ReLUs</strong>也是一种<a href="https://zh.wikipedia.org/wiki/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0" target="_blank" rel="noopener noreferrer">激活函数</a>，目前我们已经接触到的激活函数有：sigmoid，softmax，ReLUs</p></div><p>在tensorflow中，我们使用<code>tf.nn.relu()</code>来调用relu函数</p><h3 id="_3-multilayer-neural-networks"><a href="#_3-multilayer-neural-networks" aria-hidden="true" class="header-anchor">#</a> 3. Multilayer Neural Networks</h3><p>在网络中添加隐藏层可以让模型变得更复杂，同时，在隐藏层中添加非线性的激活函数，可以让模型变成非线性的。</p><p>假定我们构造一个2层的神经网络：
<img src="/udacity-self-driving-car-notes/assets/img/15380077486710.3c5f1534.jpg" alt></p><ul><li>第一层保护来一组权重和偏差，我们将X输入到这一层，并传入到激活函数<strong>ReLUs</strong>中，输出的结果会输入到下一层（隐藏层）</li><li>隐藏层将结果和本层的权重、偏差进行计算，得到输出层结果y，然后使用softmax函数将其转换为概率</li></ul><pre class="language-python"><code><span class="token comment"># Hidden Layer with ReLU activation function</span>
hidden_layer <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>features<span class="token punctuation">,</span> hidden_weights<span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_biases<span class="token punctuation">)</span>
hidden_layer <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">)</span>

output <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">,</span> output_weights<span class="token punctuation">)</span><span class="token punctuation">,</span> output_biases<span class="token punctuation">)</span>
</code></pre><h3 id="_4-链式法则及反向传播"><a href="#_4-链式法则及反向传播" aria-hidden="true" class="header-anchor">#</a> 4. 链式法则及反向传播</h3><p>这里我们同样会利用导数的链式法则，通过求解各部分导数，然后将其相乘，得到总体的导数。可以参考<a href="http://localhost:8080/udacity-self-driving-car-notes/posts/self-driving-car/deeplearning.html#%E5%AF%BC%E6%95%B0%E8%AE%A1%E7%AE%97%E4%B9%8B%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99" target="_blank" rel="noopener noreferrer">链式法则</a></p><p><img src="/udacity-self-driving-car-notes/assets/img/15380623134890.bd625fc5.jpg" alt></p><h2 id="_2-基于tensorflow的深度神经网络"><a href="#_2-基于tensorflow的深度神经网络" aria-hidden="true" class="header-anchor">#</a> 2. 基于tensorflow的深度神经网络</h2><h3 id="_1-例程"><a href="#_1-例程" aria-hidden="true" class="header-anchor">#</a> 1.  例程</h3><h4 id="学习参数"><a href="#学习参数" aria-hidden="true" class="header-anchor">#</a> 学习参数</h4><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token comment"># Parameters</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>
training_epochs <span class="token operator">=</span> <span class="token number">20</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>  <span class="token comment"># Decrease batch size if you don't have enough memory</span>
display_step <span class="token operator">=</span> <span class="token number">1</span>

n_input <span class="token operator">=</span> <span class="token number">784</span>  <span class="token comment"># MNIST data input (img shape: 28*28)</span>
n_classes <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># MNIST total classes (0-9 digits)</span>
</code></pre><h4 id="隐藏层参数"><a href="#隐藏层参数" aria-hidden="true" class="header-anchor">#</a> 隐藏层参数</h4><pre class="language-python"><code>n_hidden_layer <span class="token operator">=</span> <span class="token number">256</span> <span class="token comment"># layer number of features</span>
</code></pre><h4 id="权重和偏差"><a href="#权重和偏差" aria-hidden="true" class="header-anchor">#</a> 权重和偏差</h4><p>这里我们为不同的层创建不同的权重和偏差</p><pre class="language-python"><code><span class="token comment"># Store layers weight &amp; bias</span>
weights <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'hidden_layer'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>n_input<span class="token punctuation">,</span> n_hidden_layer<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'out'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>n_hidden_layer<span class="token punctuation">,</span> n_classes<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
biases <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'hidden_layer'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>n_hidden_layer<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'out'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>n_classes<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre><h4 id="输入"><a href="#输入" aria-hidden="true" class="header-anchor">#</a> 输入</h4><pre class="language-python"><code><span class="token comment"># tf Graph input</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span><span class="token string">&quot;float&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span><span class="token string">&quot;float&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> n_classes<span class="token punctuation">]</span><span class="token punctuation">)</span>

x_flat <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> n_input<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><h4 id="多层感知元"><a href="#多层感知元" aria-hidden="true" class="header-anchor">#</a> 多层感知元</h4><pre class="language-python"><code><span class="token comment"># Hidden layer with RELU activation</span>
layer_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_flat<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token string">'hidden_layer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>\
    biases<span class="token punctuation">[</span><span class="token string">'hidden_layer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
layer_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>layer_1<span class="token punctuation">)</span>
<span class="token comment"># Output layer with linear activation</span>
logits <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>layer_1<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token string">'out'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> biases<span class="token punctuation">[</span><span class="token string">'out'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><h4 id="优化器"><a href="#优化器" aria-hidden="true" class="header-anchor">#</a> 优化器</h4><pre class="language-python"><code><span class="token comment"># Define loss and optimizer</span>
cost <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>\
    tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax_cross_entropy_with_logits<span class="token punctuation">(</span>logits<span class="token operator">=</span>logits<span class="token punctuation">,</span> labels<span class="token operator">=</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDescentOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>\
    <span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
</code></pre><h4 id="会话"><a href="#会话" aria-hidden="true" class="header-anchor">#</a> 会话</h4><pre class="language-python"><code><span class="token comment"># Initializing the variables</span>
init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># Launch the graph</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>
    <span class="token comment"># Training cycle</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>training_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_batch <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>mnist<span class="token punctuation">.</span>train<span class="token punctuation">.</span>num_examples<span class="token operator">/</span>batch_size<span class="token punctuation">)</span>
        <span class="token comment"># Loop over all batches</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
            batch_x<span class="token punctuation">,</span> batch_y <span class="token operator">=</span> mnist<span class="token punctuation">.</span>train<span class="token punctuation">.</span>next_batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
            <span class="token comment"># Run optimization op (backprop) and cost op (to get loss value)</span>
            sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> batch_x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> batch_y<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre><h3 id="_2-训练神经网络"><a href="#_2-训练神经网络" aria-hidden="true" class="header-anchor">#</a> 2. 训练神经网络</h3><p>我们可以有两种方式来扩展我们的神经网络</p><ul><li>更广：增加隐藏层H的数量，但是参数过多会难以训练</li><li>更深：增加多层神经网络</li></ul><p>更深的方向是比较好的思路，一方面参数比较少，另一方面它会呈现出明显的结构特征，每一层可以学到不同的信息。学习速率也更快。
<img src="/udacity-self-driving-car-notes/assets/img/15380633034071.8e36902e.jpg" alt></p><p>学习完成之后，我们自然希望将结果存储下来，此时可以使用：<code>tf.train.Saver.</code></p><h3 id="_3-储存变量和模型"><a href="#_3-储存变量和模型" aria-hidden="true" class="header-anchor">#</a> 3. 储存变量和模型</h3><h4 id="储存变量"><a href="#储存变量" aria-hidden="true" class="header-anchor">#</a> 储存变量</h4><p>使用<code>tf.train.Saver.save()</code> 函数储存数据到**.ckpt格式文件中**. (checkpoint)</p><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token comment"># The file path to save the data</span>
save_file <span class="token operator">=</span> <span class="token string">'./model.ckpt'</span>

<span class="token comment"># Two Tensor Variables: weights and bias</span>
weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Class used to save and/or restore Tensor Variables</span>
saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    <span class="token comment"># Initialize all the Variables</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Show the values of weights and bias</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Weights:'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Bias:'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Save the model</span>
    saver<span class="token punctuation">.</span>save<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> save_file<span class="token punctuation">)</span>
</code></pre><h4 id="加载数据"><a href="#加载数据" aria-hidden="true" class="header-anchor">#</a> 加载数据</h4><p>因为<code>tf.train.Saver.restore()</code>函数在载入时会设置数据，不必要再调用<code>tf.global_variables_initializer().</code></p><pre class="language-python"><code><span class="token comment"># Remove the previous weights and bias</span>
tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Two Variables: weights and bias</span>
weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Class used to save and/or restore Tensor Variables</span>
saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    <span class="token comment"># Load the weights and bias</span>
    saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> save_file<span class="token punctuation">)</span>

    <span class="token comment"># Show the values of weights and bias</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Weight:'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Bias:'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><h4 id="储存完整模型"><a href="#储存完整模型" aria-hidden="true" class="header-anchor">#</a> 储存完整模型</h4><pre class="language-python"><code><span class="token keyword">import</span> math

save_file <span class="token operator">=</span> <span class="token string">'./train_model.ckpt'</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>
n_epochs <span class="token operator">=</span> <span class="token number">100</span>

saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Launch the graph</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Training cycle</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_batch <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>mnist<span class="token punctuation">.</span>train<span class="token punctuation">.</span>num_examples <span class="token operator">/</span> batch_size<span class="token punctuation">)</span>

        <span class="token comment"># Loop over all batches</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
            batch_features<span class="token punctuation">,</span> batch_labels <span class="token operator">=</span> mnist<span class="token punctuation">.</span>train<span class="token punctuation">.</span>next_batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
            sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
                optimizer<span class="token punctuation">,</span>
                feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>features<span class="token punctuation">:</span> batch_features<span class="token punctuation">,</span> labels<span class="token punctuation">:</span> batch_labels<span class="token punctuation">}</span><span class="token punctuation">)</span>

        <span class="token comment"># Print status for every 10 epochs</span>
        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            valid_accuracy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
                accuracy<span class="token punctuation">,</span>
                feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>
                    features<span class="token punctuation">:</span> mnist<span class="token punctuation">.</span>validation<span class="token punctuation">.</span>images<span class="token punctuation">,</span>
                    labels<span class="token punctuation">:</span> mnist<span class="token punctuation">.</span>validation<span class="token punctuation">.</span>labels<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch {:&lt;3} - Validation Accuracy: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                epoch<span class="token punctuation">,</span>
                valid_accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Save the model</span>
    saver<span class="token punctuation">.</span>save<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> save_file<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Trained Model Saved.'</span><span class="token punctuation">)</span>
</code></pre><h4 id="加载模型"><a href="#加载模型" aria-hidden="true" class="header-anchor">#</a> 加载模型</h4><pre class="language-python"><code>saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Launch the graph</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> save_file<span class="token punctuation">)</span>

    test_accuracy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
        accuracy<span class="token punctuation">,</span>
        feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>features<span class="token punctuation">:</span> mnist<span class="token punctuation">.</span>test<span class="token punctuation">.</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">:</span> mnist<span class="token punctuation">.</span>test<span class="token punctuation">.</span>labels<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test Accuracy: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><h3 id="_4-加载参数到新的模型"><a href="#_4-加载参数到新的模型" aria-hidden="true" class="header-anchor">#</a> 4. 加载参数到新的模型</h3><p>TensorFlow 使用<strong>name</strong>参数来标记张量和运算，如果没有设置<strong>name</strong>，则tensorflow会自动设置为<code>&lt;Type&gt;_&lt;number&gt;</code>，根据变量声明的顺序和类型来命名。因此，如果将一个模型的参数导入另一个，可能会因为顺序等原因，造成错误的自动赋值，因此我们需要手工的指定。</p><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

save_file <span class="token operator">=</span> <span class="token string">'model.ckpt'</span>

<span class="token comment"># Two Tensor Variables: weights and bias</span>
weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'weights_0'</span><span class="token punctuation">)</span>
bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'bias_0'</span><span class="token punctuation">)</span>

saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Print the name of Weights and Bias</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Save Weights: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weights<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Save Bias: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>bias<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    saver<span class="token punctuation">.</span>save<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> save_file<span class="token punctuation">)</span>

<span class="token comment"># Remove the previous weights and bias</span>
tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Two Variables: weights and bias</span>
bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'bias_0'</span><span class="token punctuation">)</span>
weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">,</span>name<span class="token operator">=</span><span class="token string">'weights_0'</span><span class="token punctuation">)</span>

saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Print the name of Weights and Bias</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load Weights: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>weights<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Load Bias: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>bias<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    <span class="token comment"># Load the weights and bias - No Error</span>
    saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> save_file<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Loaded Weights and Bias successfully.'</span><span class="token punctuation">)</span>
</code></pre><h3 id="_4-正规化"><a href="#_4-正规化" aria-hidden="true" class="header-anchor">#</a> 4. 正规化</h3><p><strong>「紧身裤」<strong>问题：紧身裤非常合身，但是难以穿上，因此我们会穿稍大一点的裤子。如果数据非常符合模型，将难以优化，因此我们会选择一个更泛化的模型，来防止出现</strong>过拟合</strong>。</p><p>防止过拟合的方法：</p><ul><li>过早终止</li><li>正则化：对神经网络进行人为的约束，使得隐式的减少参数个数。
<ol><li>L2</li><li>dropout</li></ol></li></ul><h4 id="_1-l2-正则化"><a href="#_1-l2-正则化" aria-hidden="true" class="header-anchor">#</a> 1. L2 正则化</h4><p>L2 正则化非常简单，我们只需要在loss函数上加一部分，即所有向量的平方和/2，而不需要修改模型的结构，而且它的导数也非常的简单。</p><p><img src="/udacity-self-driving-car-notes/assets/img/15380652743380.68048b89.jpg" alt></p><p><img src="/udacity-self-driving-car-notes/assets/img/15380654677950.ab0a54ea.jpg" alt></p><h4 id="_2-dropout正则化"><a href="#_2-dropout正则化" aria-hidden="true" class="header-anchor">#</a> 2. Dropout正则化</h4><p>将训练的样本随机取一半设置为0，使的网络不依赖任何给定的激活存在，因为任何激活都可能被摧毁</p><p><img src="/udacity-self-driving-car-notes/assets/img/15380658421658.c8bf5431.jpg" alt>
因此网络需要储存不同表示方法的冗余的数据
<img src="/udacity-self-driving-car-notes/assets/img/15380659683416.5bacf491.jpg" alt>
这种方法看上去有些啰嗦，实际上却可以增强网络的可靠性，并且能够防止<strong>过拟合</strong></p><p><img src="/udacity-self-driving-car-notes/assets/img/15380662426023.4fbad573.jpg" alt></p><p>The <code>tf.nn.dropout()</code> function takes in two parameters:</p><ol><li><code>hidden_layer</code>: the tensor to which you would like to apply dropout</li><li><code>keep_prob</code>: the probability of keeping (i.e. not dropping) any given unit</li></ol><p>keep_prob allows you to adjust the number of units to drop. In order to compensate for dropped units, tf.nn.dropout() multiplies all units that are kept (i.e. not dropped) by 1/keep_prob.</p><p>During training, a good starting value for keep_prob is 0.5.</p><p>During testing, use a keep_prob value of 1.0 to keep all units and maximize the power of the model</p><div class="tip custom-block"><p class="custom-block-title">扩展阅读</p></div></div><div class="content edit-link"><a href="https://github.com/hanxiaomax/udacity-self-driving-car-notes/edit/master/package/posts/self-driving-car/deepnetwork.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div><div class="content page-nav"><p class="inner"><span class="prev">
        ← <a href="/udacity-self-driving-car-notes/posts/self-driving-car/tensorflow.html" class="prev">
          深度学习库——Tensorflow
        </a></span><span class="next"><a href="/udacity-self-driving-car-notes/posts/self-driving-car/cnn.html">
          卷积神经网络
        </a> →
      </span></p></div></div></div></div>
    <script src="/udacity-self-driving-car-notes/assets/js/11.8ca08bba.js" defer></script><script src="/udacity-self-driving-car-notes/assets/js/app.f0029fc6.js" defer></script>
  </body>
</html>
