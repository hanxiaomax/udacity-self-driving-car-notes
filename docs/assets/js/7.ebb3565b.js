(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{328:function(t,a,s){"use strict";s.r(a);var n=s(0),o=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("div",{staticClass:"content"},[s("h1",{attrs:{id:"neural-networks-in-keras"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#neural-networks-in-keras","aria-hidden":"true"}},[t._v("#")]),t._v(" Neural Networks in Keras")]),s("h2",{attrs:{id:"_1-sequential-model"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-sequential-model","aria-hidden":"true"}},[t._v("#")]),t._v(" 1. Sequential Model")]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" keras"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models "),s("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Sequential\n"),s("span",{attrs:{class:"token comment"}},[t._v("# Create the Sequential model")]),t._v("\nmodel "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[s("a",{attrs:{href:"https://faroit.github.io/keras-docs/2.0.9/models/sequential/",target:"_blank",rel:"noopener noreferrer"}},[t._v("keras.models.Sequential")])]),s("h2",{attrs:{id:"_2-layers"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-layers","aria-hidden":"true"}},[t._v("#")]),t._v(" 2. Layers")]),s("p",[t._v("Layer可以用来向模型添加需要的神经网络层，使用"),s("code",[t._v("add()")]),t._v("函数进行添加：")]),s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("from keras.models import Sequential\nfrom keras.layers.core import Dense, Activation, Flatten\n\n# Create the Sequential model\nmodel = Sequential()\n\n#1st Layer - Add a flatten layer\nmodel.add(Flatten(input_shape=(32, 32, 3))) #输入32x32x3 输出为3072\n\n#2nd Layer - Add a fully connected layer\nmodel.add(Dense(100)) # 输入为3072 ，输出为100\n\n#3rd Layer - Add a ReLU activation layer\nmodel.add(Activation('relu'))\n\n#4th Layer - Add a fully connected layer\nmodel.add(Dense(60))\n\n#5th Layer - Add a ReLU activation layer\nmodel.add(Activation('relu'))\n")])]),s("p",[t._v("在Keras中你只需要设定第一层的维度，其他的Keras会自动进行推断。")]),s("h3",{attrs:{id:"例程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#例程","aria-hidden":"true"}},[t._v("#")]),t._v(" 例程")]),s("p",[t._v("构建神经网络（"),s("a",{attrs:{href:"https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py",target:"_blank",rel:"noopener noreferrer"}},[t._v("参考")]),t._v("）")]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("model "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Flatten"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input_shape"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("128")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("5")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'softmax'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{attrs:{class:"token comment"}},[t._v("# An Alternative Solution")]),t._v("\nmodel "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Flatten"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("input_shape"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("128")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("5")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token string"}},[t._v("'softmax'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("训练模型")]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{attrs:{class:"token comment"}},[t._v("# preprocess data")]),t._v("\nX_normalized "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train "),s("span",{attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("255.0")]),t._v(" "),s("span",{attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("0.5")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("preprocessing "),s("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LabelBinarizer\nlabel_binarizer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" LabelBinarizer"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_one_hot "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" label_binarizer"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_train"),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token builtin"}},[t._v("compile")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'adam'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v("'categorical_crossentropy'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{attrs:{class:"token string"}},[t._v("'accuracy'")]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nhistory "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_normalized"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_one_hot"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epochs"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" validation_split"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token number"}},[t._v("0.2")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h2",{attrs:{id:"_3-卷积神经网络"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-卷积神经网络","aria-hidden":"true"}},[t._v("#")]),t._v(" 3. 卷积神经网络")]),s("h3",{attrs:{id:"_3-1-卷积"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-卷积","aria-hidden":"true"}},[t._v("#")]),t._v(" 3.1 卷积")]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("from")]),t._v(" keras"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("convolutional "),s("span",{attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Conv2D\n"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nmodel "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Conv2D"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_shape"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Flatten"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("128")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("5")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'softmax'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h3",{attrs:{id:"_3-2-池化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-池化","aria-hidden":"true"}},[t._v("#")]),t._v(" 3.2 池化")]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("model "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Conv2D"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_shape"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MaxPooling2D"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("2")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("2")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Flatten"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("128")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("5")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'softmax'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h3",{attrs:{id:"_3-3-dropout"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-dropout","aria-hidden":"true"}},[t._v("#")]),t._v(" 3.3 Dropout")]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{attrs:{class:"token comment"}},[t._v("# Build Convolutional Pooling Neural Network with Dropout in Keras Here")]),t._v("\nmodel "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Conv2D"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_shape"),s("span",{attrs:{class:"token operator"}},[t._v("=")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("32")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("3")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MaxPooling2D"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("2")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("2")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dropout"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("0.5")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Flatten"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("128")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'relu'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token number"}},[t._v("5")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'softmax'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h2",{attrs:{id:"_4-网络性能评估"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-网络性能评估","aria-hidden":"true"}},[t._v("#")]),t._v(" 4. 网络性能评估")]),s("ul",[s("li",[s("a",{attrs:{href:"https://keras.io/models/model/#evaluate",target:"_blank",rel:"noopener noreferrer"}},[t._v("evaluate")])])]),s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("metrics "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("evaluate"),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_normalized_test"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_one_hot_test"),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" metric_i "),s("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),s("span",{attrs:{class:"token builtin"}},[t._v("range")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token builtin"}},[t._v("len")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics_names"),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    metric_name "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics_names"),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("metric_i"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    metric_value "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" metrics"),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("metric_i"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{attrs:{class:"token keyword"}},[t._v("print")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v("'{}: {}'")]),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token builtin"}},[t._v("format")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("metric_name"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metric_value"),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("20/20 [==============================] - 0s 594us/step\nloss: 0.24727313220500946\nacc: 0.75\n")])])])}],!1,null,null,null);a.default=o.exports}}]);